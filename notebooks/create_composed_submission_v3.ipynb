{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построение предсказания на основе агрегирации ответов моделей - best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from hack_lap.utils.evaluate import precision_recall, estimate_prediction, calculate_metrics_one_vs_rest_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR_DATA = os.path.join('..', 'data')\n",
    "DIR_PREDICT = os.path.join(DIR_DATA, 'predict') \n",
    "DIR_MODEL = os.path.join(DIR_DATA, 'model')\n",
    "MIN_F1 = 0.30\n",
    "\n",
    "ps = re.compile(f'seed-(\\d+)', re.I)\n",
    "pr = re.compile(f'r-(\\d+)', re.I)\n",
    "\n",
    "files_json = [n for n in os.listdir(DIR_MODEL) if n.endswith('.json') and n.startswith('b') and 'best' in n]\n",
    "\n",
    "files_by_try = defaultdict(list)\n",
    "for f in files_json:\n",
    "    seed = [int(g.group(1)) for g in ps.finditer(f)]\n",
    "    r = [int(g.group(1)) for g in pr.finditer(f)]\n",
    "    assert len(seed) == 1\n",
    "    assert len(r) == 1\n",
    "    seed = seed[0]\n",
    "    r = r[0]\n",
    "    files_by_try[(seed, r)].append(f)\n",
    "    \n",
    "files_json = []\n",
    "for _, v in files_by_try.items():\n",
    "    best_v = None\n",
    "    best_f1 = 0.0\n",
    "    for vi in v:\n",
    "        with open(os.path.join(DIR_MODEL, vi)) as fp:\n",
    "            res = json.load(fp)\n",
    "        if best_f1 < res['best_f1']:\n",
    "            best_f1 = res['best_f1']\n",
    "            best_v = vi\n",
    "    if best_f1 < MIN_F1:\n",
    "        continue\n",
    "    files_json.append((best_v, best_f1))\n",
    "len(files_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0268ebad64b3496c81577286125865d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dump_factor = np.linspace(0.9, 1.0, 11)\n",
    "predict = []\n",
    "for f_json, f1 in tqdm(files_json):\n",
    "    f = f_json.replace('json', 'pkl')\n",
    "    with open(os.path.join(DIR_MODEL, f), 'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "    yt_dev, yp_dev, yp_test = data['yt_dev'], data['yp_dev'], data['yp_test']\n",
    "    \n",
    "    score = []\n",
    "    for f in dump_factor:\n",
    "        _, (_, _, f11) = calculate_metrics_one_vs_rest_(yt_dev, yp_dev, dump_factor=f)\n",
    "        score.append(f11)\n",
    "    ss = np.nanargmax(score)\n",
    "    \n",
    "\n",
    "    yp_dev = np.mean(yp_dev, axis=1).ravel()\n",
    "    rp0, rp1, th = precision_recall(yt_dev, yp_dev)\n",
    "    f1 = 2 * rp1[0] * rp1[1] / (rp1[0] + rp1[1] + 1e-6)\n",
    "    ii = np.argmax(f1)\n",
    "    f1 = f1[ii]\n",
    "    th = th[ii]\n",
    "\n",
    "    yp_test = np.mean(yp_test, axis=1)\n",
    "    yp_test = (yp_test > th * dump_factor[ss]).astype(int).reshape(-1, 1)\n",
    "    predict.append(yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "# active: 25\n"
     ]
    }
   ],
   "source": [
    "submission = np.concatenate(predict, axis=1)\n",
    "print(submission.shape[1])\n",
    "submission = np.mean(submission, axis=1)\n",
    "th = 0.5\n",
    "cls_pred = (submission > th).astype(int)\n",
    "print(f'# active: {np.sum(cls_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b-L4-H32-Patt-NF-BF-#seeds-44_hash--1757033375511565524_mean_th-0.5\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DIR_DATA, 'test.csv'))\n",
    "df['Active'] = submission\n",
    "\n",
    "seeds = tuple(sorted(files_by_try.keys()))\n",
    "seed_hash = hash(''.join(map(str, seeds)))\n",
    "name = f'b-L4-H32-Patt-NF-BF-#seeds-{len(seeds)}_hash-{seed_hash}_mean_th-{th}'\n",
    "\n",
    "print(name)\n",
    "df.to_csv(os.path.join(DIR_PREDICT, name + '.csv'), index=False)\n",
    "\n",
    "with open(os.path.join(DIR_PREDICT, name + '.json'), 'w') as fp:\n",
    "    json.dump({'seeds': seeds}, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon: lap",
   "language": "python",
   "name": "hackathon-lap"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
